---
output: github_document
---
<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/",
  out.width = "100%",
  fig.align='left'
)
```
<br>
<br>

# ConversationAlign
Open-source software for computing main effects and indices of alignment across coversation partners in dyadic conversation transcripts. <br>

```{r echo=FALSE, results='asis'}
# Get current package version from DESCRIPTION
if (!requireNamespace("desc", quietly = TRUE)) {
  install.packages("desc")
}
pkg_version <- desc::desc_get_version(file = "DESCRIPTION")

# Generate badges with HTML wrapper for horizontal layout
cat('<div style="display: flex; gap: 10px; flex-wrap: wrap; margin-bottom: 15px;">')

# GitHub Release badge with specific version
cat(sprintf('[![GitHub release](https://img.shields.io/github/v/release/Reilly-ConceptsCognitionLab/ConversationAlign?color=blue&include_prereleases&label=Release&v=%s)](https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign/releases)', pkg_version))

# GitHub Stars badge
cat('
[![GitHub stars](https://img.shields.io/github/stars/Reilly-ConceptsCognitionLab/ConversationAlign?style=social)](https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign/stargazers)
')

# Other badges
cat('
[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign/graphs/commit-activity)
[![License: GPL v3+](https://img.shields.io/badge/License-GPL%20v3+-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![R-CMD-check](https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign/actions/workflows/R-CMD-check.yaml)
')

cat('</div>')  # Close flex container

```

  
<img src="man/figures/convo_demo.jpg" 
     alt="illustration of processing pipeline used by ConversationAlign" 
     style="float: right; width: 60%; margin-left: 20px; margin-bottom: 10px;" />

# Overview
`ConversationAlign` analyzes alignment and computes main effects across more than 40 unique dimensions between interlocutors (conversation partners) engaged in two-person conversations.  ConversationAlign transforms raw language data into simultaneous time series objects across >40 possible dimensions via an embedded lookup database. There are a number of issues you should consider and steps you should take to prepare your data. 

# Installation
Install the development version of ConversationAlign from [GitHub](https://github.com/) using the ``devtools`` package.

```{r, message=FALSE, warning=F}
# Check if devtools is installed, if not install it
if (!require("devtools", quietly = TRUE)) {
  install.packages("devtools")
}

# Load devtools
library(devtools)

# Check if ConversationAlign is installed, if not install from GitHub
if (!require("ConversationAlign", quietly = TRUE)) {
  devtools::install_github("Reilly-ConceptsCognitionLab/ConversationAlign")
}

# Load SemanticDistance
library(ConversationAlign)
```


# Step 1: Read and Format Transcript Options
## `read_dyads()`  
- Reads transcripts from a local drive or directory of your choice. 
- Store each of your  individual conversation transcripts (`.csv`, `.txt`, `.ai`) that you wish to concatenate into a corpus in a folder. `ConversationAlign` will search for a folder called `my_transcripts` in the same directory as your script.  However, feel free to name your folder anything you like. You can specify a custom path as an argument to read_dyads()
- Each transcript must nominally contain two columns of data (Participant and Text). All other columns (e.g., meta-data) will be retained. 

<span style="color: darkred;">Arguments to `read_dyads` include:</span>  <br>
1. **my_path**: default is 'my_transcripts', change path to your folder name<br>
```{r, eval=F, message=F, warning=F}
#will search for folder 'my_transcripts' in your current directory
MyConvos <- read_dyads()

#will scan custom folder called 'MyStuff' in your current directory, concatenating all files in that folder into a single dataframe
MyConvos2 <- read_dyads(my_path='/MyStuff')
```

## `read_1file()`
- Read single transcript already in R environment. We will use read_1file() to prep the Marc Maron and Terry Gross transcript. Look at how the column headers have changed and the object name (MaronGross_2013) is now the Event_ID (a document identifier), <br>

<span style="color: darkred;">Arguments to `read_1file` include:</span>  <br>
1. **my_dat**: object already in your R environment containing text and speaker information.
```{r, eval=T, message=F, warning=F}
MaryLittleLamb <- read_1file(MaronGross_2013)
#print first ten rows of header
knitr::kable(head(MaronGross_2013, 15), format = "pipe")
```
<br>

# Step 2: Clean, Format, Align Norms
## `prep_dyads()`
-Cleans, formats, and vectorizes conversation transwcripts to a one-word-per-row format
-Yokes psycholinguistic norms for up to three dimensions at a time (from <40 possible dimensions) to each content word.
-Retains metadata

<span style="color: darkred;">Arguments to `prep_dyads`:</span> <br>
1) **dat_read**= name of the dataframe created during `read_dyads()` <br>
2) **omit_stops**= T/F (default=T) option to remove stopwords
3) **lemmatize**= lemmatize strings converting each entry to its dictionary form, default is `lemmatize=TRUE` <br>
4) **which_stoplist**= quoted argument specifying stopword list, options include ``none``, ``MIT_stops``, ``SMART``, ``CA_OriginalStops``, or ``Temple_stops25``. Default is ``Temple_stops25``
```{r, eval=F, message=F, warning=F}
NurseryRhymes_Prepped <- prep_dyads(dat_read=NurseryRhymes, lemmatize=TRUE, omit_stops=T, which_stoplist="Temple_stops25")
```

Example of a prepped dataset embedded as external data in the package with 'anger' values yoked to each word.
```{r}
knitr::kable(head(NurseryRhymes_Prepped, 20), format = "simple", digits=2)
```

# Step 3: Summarize Data, Alignment Stats 
## `summarize_dyads()`
This is the computational stage where the package generates a dataframe boiled down to two rows per converation with summary data appended to each level of Participant_ID. This returns the difference time series AUC (dAUC) for every variable of interest you specified and the correlation at lags -2,,0, 2. You decide whether you want a Pearson or Spearman lagged correlation. <br>

<span style="color: darkred;">Arguments to ``summarize_dyads()`` include:</span> <br>
1) **df_prep**= dataframe created by ``prep_dyads()``function <br>
2) **custom_lags**=  default is NULL, any additional user-specified lagged correlations. will automatically produce lead of 2 turns, immediate response, lag of 2 turns for each dimension of interest. <br>
3) **sumdat_only**= boolean default is TRUE, produces grouped summary dataframe with averages by conversation and participant for each alignment dimension, FALSE retrains all of the original rows, filling down empty rows of summary statistics for the conversation (e.g., AUC) <br>
4) **corr_type**= default='Pearson', other option 'Spearman' for computing turn-by-turn correlations across interlocutors for each dimension of interest.
```{r, eval=T, warning=F, message=F, options(digits = 3)}
MarySumDat <- summarize_dyads(df_prep = NurseryRhymes_Prepped, custom_lags=NULL, sumdat_only = TRUE, corr_type='Pearson') 
colnames(MarySumDat)
knitr::kable(head(MarySumDat, 15), format = "simple", digits = 3)
```

# Optional: Generate corpus analytics 
## `corpus_analytics()`
It is often critical to produce descriptives/summary statistics to characterize your language sample. This is typically a laborious process. ``corpus_analytics`` will do it for you, generating a near publication ready table of analytics that you can easily export to the specific journal format of your choice using any number of packages such as `flextable` or `tinytable`.

<span style="color: darkred;">Arguments to `corpus_analytics` include:</span> <br>
1) **dat_prep**= dataframe created by ``prep_dyads()``function <br>

```{r, eval=T, warning=F, message=F}
NurseryRhymes_Analytics <-  corpus_analytics(dat_prep=NurseryRhymes_Prepped)
knitr::kable(head(NurseryRhymes_Analytics, 15), format = "simple", digits = 2)
```


# News and Getting Help
For bugs, feature requests, and general questions, reach out via one of the following options: <br>
<ul style="list-style-type: none; padding-left: 0;">
  <li><strong>Bugs/Features:</strong><br>[Open an Issue](https://github.com/Reilly-ConceptsCognitionLab/ConversationAlign/issues)</li>
  <li><strong>Questions:</strong><br>[Join Discussion](https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance/discussions)</li>
  <li><strong>Urgent:</strong><br>Email <code>jamie.reilly@temple.edu</code></li>
</ul>
